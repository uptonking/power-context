services:
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant-db
    # Expose Qdrant database APIs to the host
    # 6333 = HTTP API, 6334 = gRPC
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage

  mcp:
    build:
      context: .
      dockerfile: Dockerfile.mcp
    container_name: mcp-search
    depends_on:
      - qdrant
    env_file:
      - .env
    environment:
      # Ensure the server binds to all interfaces for container networking
      - FASTMCP_HOST=${FASTMCP_HOST}
      - FASTMCP_PORT=${FASTMCP_PORT}
      - QDRANT_URL=${QDRANT_URL}
      - COLLECTION_NAME=${COLLECTION_NAME}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER}
      - TOOL_STORE_DESCRIPTION=${TOOL_STORE_DESCRIPTION}
      - TOOL_FIND_DESCRIPTION=${TOOL_FIND_DESCRIPTION}
      - FASTMCP_HEALTH_PORT=18000

    # SSE endpoint for IDE agents at http://localhost:8000/sse
    ports:
      - "18000:18000"

      - "8000:8000"

    volumes:
      - ${HOST_INDEX_PATH:-.}:/work:ro

  mcp_indexer:
    build:
      context: .
      dockerfile: Dockerfile.mcp-indexer
    container_name: mcp-indexer
    depends_on:
      - qdrant
    env_file:
      - .env
    environment:
      - FASTMCP_HEALTH_PORT=18001

      - FASTMCP_HOST=${FASTMCP_HOST}
      - FASTMCP_INDEXER_PORT=${FASTMCP_INDEXER_PORT}
      - QDRANT_URL=${QDRANT_URL}
    # SSE endpoint for IDE agents at http://localhost:${FASTMCP_INDEXER_PORT:-8001}/sse
    ports:
      - "${FASTMCP_INDEXER_PORT:-8001}:8001"
      - "18001:18001"
    volumes:
      - ${HOST_INDEX_PATH:-.}:/work

  llamacpp:
    image: ghcr.io/ggerganov/llama.cpp:server
    container_name: llama-decoder
    # Optional sidecar providing a text-generation API on :8080
    # No behavior change unless REFRAG_DECODER=1
    environment:
      - LLAMA_ARG_MODEL=/models/model.gguf
      - LLAMA_ARG_CTX_SIZE=8192
      - LLAMA_ARG_HOST=0.0.0.0
      - LLAMA_ARG_PORT=8080
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models:ro
    # The server image's entrypoint is already the server binary; pass args only
    command: ["--model", "/models/model.gguf", "--host", "0.0.0.0", "--port", "8080", "--no-warmup"]


  indexer:
    build:
      context: .
      dockerfile: Dockerfile.indexer
    depends_on:
      - qdrant
    env_file:
      - .env
    environment:
      - QDRANT_URL=${QDRANT_URL}
      - COLLECTION_NAME=${COLLECTION_NAME}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
    working_dir: /work
    volumes:
      - ${HOST_INDEX_PATH:-.}:/work:ro
    entrypoint: ["python", "scripts/ingest_code.py"]

  watcher:
    build:
      context: .
      dockerfile: Dockerfile.indexer
    depends_on:
      - qdrant
    env_file:
      - .env
    environment:
      - QDRANT_URL=${QDRANT_URL}
      - COLLECTION_NAME=${COLLECTION_NAME}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - WATCH_ROOT=/work
      # Watcher-specific backpressure & timeouts (safer defaults)
      - QDRANT_TIMEOUT=60
      - MAX_MICRO_CHUNKS_PER_FILE=200
      - INDEX_UPSERT_BATCH=128
      - INDEX_UPSERT_RETRIES=5
      - WATCH_DEBOUNCE_SECS=1.5
    working_dir: /work
    volumes:
      - ${HOST_INDEX_PATH:-.}:/work:ro
    entrypoint: ["python", "scripts/watch_index.py"]

  init_payload:
    build:
      context: .
      dockerfile: Dockerfile.indexer
    depends_on:
      - qdrant
    env_file:
      - .env
    environment:
      - QDRANT_URL=${QDRANT_URL}
      - COLLECTION_NAME=${COLLECTION_NAME}
    working_dir: /work
    volumes:
      - ${HOST_INDEX_PATH:-.}:/work:ro
    entrypoint: ["python", "scripts/create_indexes.py"]

volumes:
  qdrant_storage:
    driver: local

