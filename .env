# Environment for local Qdrant + MCP server (SSE)
# Qdrant (vector DB) runs as docker service "qdrant". The MCP server connects to it internally.
QDRANT_URL=http://qdrant:6333
# QDRANT_API_KEY= # not needed for local

# Default collection used by the MCP server (auto-created if missing)
COLLECTION_NAME=my-collection

# Embedding settings (FastEmbed model)
EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
EMBEDDING_PROVIDER=fastembed

# FastMCP server settings (SSE transport)
FASTMCP_HOST=0.0.0.0
FASTMCP_PORT=8000
FASTMCP_INDEXER_PORT=8001

# Optional: customize tool descriptions (uncomment to use)
TOOL_STORE_DESCRIPTION="Store reusable code snippets for later retrieval. The 'information' is a clear NL description; include the actual code in 'metadata.code' and add 'metadata.language' (e.g., python, typescript) and 'metadata.path' when known. Use this whenever you generate or refine a code snippet."
TOOL_FIND_DESCRIPTION="Search for relevant code snippets using multiple phrasings of the query (multi-query). Prefer results where metadata.language matches the target file and metadata.path is relevant. You may pass optional filters (language, path_prefix, kind) which the server applies server-side. Include 'metadata.code', 'metadata.path', and 'metadata.language' in responses."



# Optional: local cross-encoder reranker (ONNX)
# Set these to enable make rerank-local inside the container
RERANKER_ONNX_PATH=/work/models/model_qint8_avx512_vnni.onnx
RERANKER_TOKENIZER_PATH=/work/models/tokenizer.json

# Reranker toggles and tuning
# Increased TOPN and RETURN_M for better final ranking
RERANKER_ENABLED=1
RERANKER_TOPN=100
RERANKER_RETURN_M=20
RERANKER_TIMEOUT_MS=3000

# Safety: minimum rerank timeout floor (ms) to avoid cold-start timeouts
RERANK_TIMEOUT_FLOOR_MS=1000

# Optional warmups (disabled by default)
EMBEDDING_WARMUP=0
RERANK_WARMUP=0


# In-process execution (faster; falls back to subprocess on failure)
HYBRID_IN_PROCESS=1
RERANK_IN_PROCESS=1


# Tree-sitter parsing (enable for more accurate symbols/scopes)
USE_TREE_SITTER=1


# Hybrid/rerank quick-win defaults (can override via flags)
HYBRID_EXPAND=1
HYBRID_PER_PATH=1
# Increased symbol boost to prioritize function/class definitions
HYBRID_SYMBOL_BOOST=0.35
HYBRID_RECENCY_WEIGHT=0.1
RERANK_EXPAND=1

# Disable semantic chunking to use micro-chunking instead
INDEX_SEMANTIC_CHUNKS=0


# Memory integration (SSE + Qdrant)
MEMORY_SSE_ENABLED=true
MEMORY_MCP_URL=http://mcp:8000/sse
MEMORY_MCP_TIMEOUT=6


# Local LLM expansion via Ollama (mini model)
LLM_PROVIDER=ollama
OLLAMA_HOST=http://host.docker.internal:11434
LLM_EXPAND_MODEL=phi3:mini
LLM_EXPAND_MAX=4
# PRF defaults (enabled by default)
PRF_ENABLED=1


# ReFRAG mode: compact gating + micro-chunking
REFRAG_MODE=1
MINI_VECTOR_NAME=mini
MINI_VEC_DIM=64
MINI_VEC_SEED=1337
HYBRID_MINI_WEIGHT=1.0
# Micro-chunking controls (token-based)
# Smaller chunks = more precise retrieval (8 tokens ~= 2-3 lines of code)
INDEX_MICRO_CHUNKS=1
MICRO_CHUNK_TOKENS=8
MICRO_CHUNK_STRIDE=4
# Optional: gate-first using mini vectors to prefilter dense search
REFRAG_GATE_FIRST=1
REFRAG_CANDIDATES=200

# Output shaping for micro spans
# Conservative settings for small 1.5B model (Qwen2.5-Coder-1.5B)
MICRO_OUT_MAX_SPANS=3
MICRO_MERGE_LINES=4
MICRO_BUDGET_TOKENS=1500
MICRO_TOKENS_PER_LINE=32


# Answer shaping (enforce concise responses from context_answer)
CTX_SUMMARY_CHARS=0

# Decoder-path ReFRAG (feature-flagged; off by default)
REFRAG_DECODER=1
REFRAG_RUNTIME=llamacpp
REFRAG_ENCODER_MODEL=BAAI/bge-base-en-v1.5
REFRAG_PHI_PATH=/work/models/refrag_phi_768_to_dmodel.bin
REFRAG_SENSE=heuristic

# Llama.cpp sidecar (optional)
# Use docker network hostname from containers; localhost remains ok for host-side runs if LLAMACPP_URL not exported
LLAMACPP_URL=http://llamacpp:8080
LLAMACPP_TIMEOUT_SEC=120
DECODER_MAX_TOKENS=150
REFRAG_DECODER_MODE=prompt  # prompt|soft

REFRAG_SOFT_SCALE=1.0


# Operational safeguards and timeouts
MAX_MICRO_CHUNKS_PER_FILE=200
QDRANT_TIMEOUT=20
MEMORY_AUTODETECT=1
MEMORY_COLLECTION_TTL_SECS=300


# Watcher-safe defaults (recommended)
# These are applied to the watcher service via docker-compose.yml.
# Uncomment to apply globally if you are not using compose overrides.
# QDRANT_TIMEOUT=60
# MAX_MICRO_CHUNKS_PER_FILE=200
# INDEX_UPSERT_BATCH=128
# INDEX_UPSERT_RETRIES=5
# INDEX_UPSERT_BACKOFF=0.5
# WATCH_DEBOUNCE_SECS=1.5


# Duplicate Streamable HTTP MCP instances (run alongside SSE)
FASTMCP_HTTP_TRANSPORT=http
FASTMCP_HTTP_PORT=8002
FASTMCP_HTTP_HEALTH_PORT=18002
FASTMCP_INDEXER_HTTP_PORT=8003
FASTMCP_INDEXER_HTTP_HEALTH_PORT=18003
