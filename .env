# Environment for local Qdrant + MCP server (SSE)
# Qdrant (vector DB) runs as docker service "qdrant". The MCP server connects to it internally.
QDRANT_URL=http://qdrant:6333
# QDRANT_API_KEY= # not needed for local

# Repository mode: 0=single-repo (default), 1=multi-repo
# Single-repo: All files go into one collection (COLLECTION_NAME)
# Multi-repo: Each subdirectory gets its own collection
MULTI_REPO_MODE=0

# Single unified collection for seamless cross-repo search
# Default: "codebase" - all your code in one collection for unified search
# This enables searching across multiple repos/workspaces without fragmentation
COLLECTION_NAME=codebase

# Embedding settings (FastEmbed model)
EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
EMBEDDING_PROVIDER=fastembed

# FastMCP server settings (SSE transport)
FASTMCP_HOST=0.0.0.0
FASTMCP_PORT=8000
FASTMCP_INDEXER_PORT=8001

# Optional: customize tool descriptions (uncomment to use)
TOOL_STORE_DESCRIPTION="Store reusable code snippets for later retrieval. The 'information' is a clear NL description; include the actual code in 'metadata.code' and add 'metadata.language' (e.g., python, typescript) and 'metadata.path' when known. Use this whenever you generate or refine a code snippet."
TOOL_FIND_DESCRIPTION="Search for relevant code snippets using multiple phrasings of the query (multi-query). Prefer results where metadata.language matches the target file and metadata.path is relevant. You may pass optional filters (language, path_prefix, kind) which the server applies server-side. Include 'metadata.code', 'metadata.path', and 'metadata.language' in responses."



# Optional: local cross-encoder reranker (ONNX)
# Baked into Docker image at /app/models/ - no host mount needed
RERANKER_ONNX_PATH=/app/models/reranker.onnx
RERANKER_TOKENIZER_PATH=/app/models/tokenizer.json

# Reranker toggles and tuning
# Increased TOPN and RETURN_M for better final ranking
RERANKER_ENABLED=1
RERANKER_TOPN=100
RERANKER_RETURN_M=20
RERANKER_TIMEOUT_MS=3000

# Safety: minimum rerank timeout floor (ms) to avoid cold-start timeouts
RERANK_TIMEOUT_FLOOR_MS=1000

# Optional warmups (disabled by default)
EMBEDDING_WARMUP=0
RERANK_WARMUP=0


# In-process execution (faster; falls back to subprocess on failure)
HYBRID_IN_PROCESS=1
RERANK_IN_PROCESS=1


# Query Optimization (adaptive HNSW_EF tuning for 2x faster simple queries)
QUERY_OPTIMIZER_ADAPTIVE=1
QUERY_OPTIMIZER_MIN_EF=64
QUERY_OPTIMIZER_MAX_EF=512
QUERY_OPTIMIZER_SIMPLE_THRESHOLD=0.3
QUERY_OPTIMIZER_COMPLEX_THRESHOLD=0.7
QUERY_OPTIMIZER_SIMPLE_FACTOR=0.5
QUERY_OPTIMIZER_SEMANTIC_FACTOR=1.0
QUERY_OPTIMIZER_COMPLEX_FACTOR=2.0
QUERY_OPTIMIZER_DENSE_THRESHOLD=0.2
QUERY_OPTIMIZER_COLLECTION_SIZE=10000
QDRANT_EF_SEARCH=128

# AST-based code understanding (semantic chunking for 20-30% better precision)
USE_TREE_SITTER=1
INDEX_USE_ENHANCED_AST=1
INDEX_SEMANTIC_CHUNKS=1

# Hybrid/rerank defaults
HYBRID_EXPAND=0
HYBRID_PER_PATH=1
HYBRID_SYMBOL_BOOST=0.35
HYBRID_RECENCY_WEIGHT=0.1
RERANK_EXPAND=1


# Memory integration (SSE + Qdrant)
MEMORY_SSE_ENABLED=true
MEMORY_MCP_URL=http://mcp:8000/sse
MEMORY_MCP_TIMEOUT=6


# Local LLM expansion via Ollama (mini model)
LLM_PROVIDER=ollama
OLLAMA_HOST=http://host.docker.internal:11434
LLM_EXPAND_MODEL=phi3:mini
LLM_EXPAND_MAX=0
# PRF defaults (enabled by default)
PRF_ENABLED=1


# ReFRAG mode: compact gating + micro-chunking
REFRAG_MODE=1
MINI_VECTOR_NAME=mini
MINI_VEC_DIM=64
MINI_VEC_SEED=1337
HYBRID_MINI_WEIGHT=1.0
# Micro-chunking controls (token-based)
# Smaller chunks = more precise retrieval (8 tokens ~= 2-3 lines of code)
INDEX_MICRO_CHUNKS=0
MICRO_CHUNK_TOKENS=24
MICRO_CHUNK_STRIDE=48
# Optional: gate-first using mini vectors to prefilter dense search
REFRAG_GATE_FIRST=1
REFRAG_CANDIDATES=200

# Output shaping for micro spans
# Conservative settings
MICRO_OUT_MAX_SPANS=3
MICRO_MERGE_LINES=4
MICRO_BUDGET_TOKENS=1500
MICRO_TOKENS_PER_LINE=32


# Answer shaping (enforce concise responses from context_answer)
CTX_SUMMARY_CHARS=0
CTX_SNIPPET_CHARS=400


# Decoder-path ReFRAG
REFRAG_DECODER=1
REFRAG_RUNTIME=llamacpp
REFRAG_ENCODER_MODEL=BAAI/bge-base-en-v1.5
REFRAG_PHI_PATH=/work/models/refrag_phi_768_to_dmodel.bin
REFRAG_SENSE=heuristic
GLM_API_KEY=
# Llama.cpp sidecar (optional)
# Use docker network hostname from containers; localhost remains ok for host-side runs if LLAMACPP_URL not exported
LLAMACPP_URL=http://host.docker.internal:8081
LLAMACPP_TIMEOUT_SEC=300
DECODER_MAX_TOKENS=4000
REFRAG_DECODER_MODE=prompt  # prompt|soft

REFRAG_SOFT_SCALE=1.0
LLAMACPP_USE_GPU=1
LLAMACPP_GPU_LAYERS=32
LLAMACPP_THREADS=6
LLAMACPP_GPU_SPLIT=
LLAMACPP_EXTRA_ARGS=


# Operational safeguards and timeouts
MAX_MICRO_CHUNKS_PER_FILE=500
QDRANT_TIMEOUT=20
MEMORY_AUTODETECT=1
MEMORY_COLLECTION_TTL_SECS=300


# Watcher-safe defaults (recommended)
# These are applied to the watcher service via docker-compose.yml.
# Uncomment to apply globally if you are not using compose overrides.
# QDRANT_TIMEOUT=60
# MAX_MICRO_CHUNKS_PER_FILE=200
# INDEX_UPSERT_BATCH=128
# INDEX_UPSERT_RETRIES=5
# INDEX_UPSERT_BACKOFF=0.5
WATCH_DEBOUNCE_SECS=4


# Duplicate Streamable HTTP MCP instances (run alongside SSE)
FASTMCP_HTTP_TRANSPORT=http
FASTMCP_HTTP_PORT=8002
FASTMCP_HTTP_HEALTH_PORT=18002
FASTMCP_INDEXER_HTTP_PORT=8003
FASTMCP_INDEXER_HTTP_HEALTH_PORT=18003


MAX_EMBED_CACHE=16384
HYBRID_RESULTS_CACHE=128
HYBRID_RESULTS_CACHE_ENABLED=1
INDEX_CHUNK_LINES=60
INDEX_CHUNK_OVERLAP=10
USE_GPU_DECODER=0

# Development Remote Upload Configuration
HOST_INDEX_PATH=./dev-workspace

# Cross-Codebase Isolation (multi-repo search scoping)
# When enabled, search results are automatically filtered to the current repo
REPO_AUTO_FILTER=1
# Explicitly set current repo (overrides auto-detection from git/directory)
# CURRENT_REPO=

# Post-rerank symbol boost: ensures exact symbol matches rank highest
POST_RERANK_SYMBOL_BOOST=1.0
# Rerank blend weight: ratio of rerank score vs fusion score (0.0-1.0)
RERANK_BLEND_WEIGHT=0.6

# info_request() tool settings (simplified codebase retrieval)
INFO_REQUEST_LIMIT=10
INFO_REQUEST_CONTEXT_LINES=5
# INFO_REQUEST_EXPLAIN_DEFAULT=0
# INFO_REQUEST_RELATIONSHIPS=0
COMMIT_VECTOR_SEARCH=0
